{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120c408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (2.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install haversine\n",
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "import glob\n",
    "import s3fs\n",
    "import unittest\n",
    "import numpy as np\n",
    "import os\n",
    "from dma_functions import get_dma, get_dma_zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54047c01",
   "metadata": {},
   "source": [
    "DATASETS (NECESSARY FOR FUNCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c673db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in centroids data\n",
    "centroids_df = pd.read_csv(\"./data/evaluation_data/zipcode_centroids.csv\",\n",
    "                        dtype={\"ZIP\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88633214",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43dd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a sentence into multiple sentences segmented on DMA\n",
    "def split_by_dma(sentence):\n",
    "    # If this sentence is one zipcode long, do nothing\n",
    "    if len(sentence) == 1:\n",
    "        return [sentence]\n",
    "    else:\n",
    "        sentence_split = []\n",
    "        start_index = 0\n",
    "        start_dma = get_dma(sentence[start_index])\n",
    "        for i in range(1, len(sentence)):\n",
    "            if get_dma(sentence[i]) != start_dma:\n",
    "                sentence_split.append(sentence[start_index:i])\n",
    "                start_index = i\n",
    "                start_dma = get_dma(sentence[start_index])\n",
    "                # If this is the last zipcode in the sentence, make sure to add it on\n",
    "                if i == len(sentence) - 1:\n",
    "                    sentence_split.append([sentence[i]])\n",
    "            # If this is the last zipcode and it isn't a change in dma, add sentence from start_index to this index\n",
    "            elif i == len(sentence) - 1:\n",
    "                sentence_split.append(sentence[start_index:i + 1])\n",
    "        return sentence_split\n",
    "\n",
    "# Merge list of sentences based on common DMA\n",
    "def merge_by_dma(sentences, merged_sentences):\n",
    "    # Base case: if sentences has no zipcodes left, return merged_sentences\n",
    "    if (len(sentences) == 0) or (len(sentences) == 1 and len(sentences[0]) == 0):\n",
    "        return merged_sentences\n",
    "    # If sentences only has one zipcode left, concatenate to merged_sentences and return\n",
    "    elif len(sentences) == 1 and len(sentences[0]) != 0:\n",
    "        return merged_sentences + sentences\n",
    "    else:\n",
    "        # Get all indices that have same DMA as first sentence\n",
    "        start_dma = get_dma(sentences[0])\n",
    "        same_indices = [0]\n",
    "        combined_sentence = sentences[0]\n",
    "        # Combine all same DMA sentences into one\n",
    "        for i in range(1, len(sentences)):\n",
    "            if get_dma(sentences[i]) == start_dma:\n",
    "                same_indices.append(i)\n",
    "                combined_sentence = combined_sentence + sentences[i]\n",
    "        merged_sentences = merged_sentences + [combined_sentence]\n",
    "        # Only use non-same (not examined) indices\n",
    "        sentences_dropped = [s for s in sentences if sentences.index(s) not in same_indices]\n",
    "        return merge_by_dma(sentences_dropped, merged_sentences)\n",
    "    \n",
    "def convert_four_digit_zip(zipcode):\n",
    "    # If zip is longer than 4 digits, return same zipcode\n",
    "    if len(zipcode) > 4:\n",
    "        return zipcode\n",
    "    elif len(zipcode) == 4:\n",
    "        return \"0\" + zipcode\n",
    "    else:\n",
    "        raise Exception('Invalid zipcode/zipcode length')\n",
    "        \n",
    "def calc_distance(zip1, zip2):\n",
    "    zip1_data = centroids_df[centroids_df[\"ZIP\"] == zip1]\n",
    "    zip2_data = centroids_df[centroids_df[\"ZIP\"] == zip2]\n",
    "    if len(zip1_data) == 0 or len(zip2_data) == 0:\n",
    "        return None\n",
    "    else: \n",
    "        zip1_coords = (zip1_data.LAT.values[0], zip1_data.LNG.values[0])\n",
    "        zip2_coords = (zip2_data.LAT.values[0], zip2_data.LNG.values[0])\n",
    "        return haversine(zip1_coords, zip2_coords)\n",
    "\n",
    "# Get negative sample (closest geographic zipcode)\n",
    "def get_negative(anchor):\n",
    "    # Get all zipcodes in this zipcode's DMA\n",
    "    dma_zipcodes = get_dma_zipcodes(get_dma(anchor))\n",
    "    # Remove anchor from dma_zipcodes\n",
    "    anchor_index = np.where(dma_zipcodes == anchor)\n",
    "    dma_zipcodes = np.delete(dma_zipcodes, anchor_index)\n",
    "    \n",
    "    # Find smallest distance and zipcode\n",
    "    min_index = -1\n",
    "    min_value = float(\"inf\")\n",
    "    for index, zipcode in enumerate(dma_zipcodes):\n",
    "        current_distance = calc_distance(anchor, zipcode)\n",
    "        # Check if current_distance is None ie either the anchor or comparison zipcode doesn't have data\n",
    "        if current_distance == None:\n",
    "            continue\n",
    "        elif current_distance < min_value:\n",
    "            min_index = index\n",
    "            min_value = current_distance\n",
    "    \n",
    "    return dma_zipcodes[min_index], min_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9d676",
   "metadata": {},
   "source": [
    "MODIFY AND AUGMENT CLICKSTREAM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef9d2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clickstream v2 Data\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "PATH = \"s3://ojo-data-science/glen/clickstream_v2_clean/\"\n",
    "# Use glob to get all the csv files in the folder\n",
    "csv_files = s3.glob(os.path.join(PATH, \"*.csv\"))\n",
    "\n",
    "# Loop over list of csv files\n",
    "dataframes = []\n",
    "for file_path in csv_files:\n",
    "    file = pd.read_csv(\"s3://\" + file_path, \n",
    "                       header=None, \n",
    "                       names=[\"unique_visit_id\", \"first_char\", \"sentences\"],\n",
    "                       converters={'sentences': lambda x: x[1:-1].split(',')})\n",
    "    dataframes.append(file)\n",
    "    \n",
    "clickstream_v2 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# clickstream_v2.to_csv(\"clickstream_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean = all zipcodes start with same digit\n",
    "# length = length of sentence\n",
    "clean = [True for i in range(len(clickstream_v2.index))]\n",
    "length = [-1 for i in range(len(clickstream_v2.index))]\n",
    "\n",
    "for index, row in clickstream_v2.iterrows():\n",
    "    clean_counter = True\n",
    "    for zipcode in row[\"sentences\"]:\n",
    "        if str(row[\"first_char\"]) != zipcode[0]:\n",
    "            clean_counter = False\n",
    "            break\n",
    "    clean[index] = clean_counter\n",
    "    length[index] = len(row[\"sentences\"])\n",
    "    \n",
    "clickstream_v2[\"clean\"] = clean\n",
    "clickstream_v2[\"length\"] = length\n",
    "\n",
    "# clickstream_v2.to_csv(\"clickstream_v2_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800d6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstream_v2 = pd.read_csv(\"./data/training_data/clickstream_v2_augmented.csv\",\n",
    "                            converters={\"sentences\": lambda x: x[1:-1].replace(\"'\", \"\").replace(\" \", \"\").split(',')})\n",
    "\n",
    "# Split and merge clickstream_v2 sentences by DMA (through multiple dataframes)\n",
    "clickstream_v2_dma = clickstream_v2.copy()\n",
    "        \n",
    "# Get clickstream_dma data\n",
    "clickstream_v2_dma[\"sentences_dma\"] = clickstream_v2_dma[\"sentences\"].apply(lambda x: merge_by_dma(split_by_dma(x), []))\n",
    "clickstream_v2_dma = clickstream_v2_dma.explode(\"sentences_dma\", ignore_index=True)\n",
    "clickstream_v2_dma.to_csv(\"clickstream_v2_dma.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3b878",
   "metadata": {},
   "source": [
    "GET NEGATIVE ZIPCODES FOR TRANSACTION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4425512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Transaction Zipcodes data to run tests\n",
    "transactions_df = pd.read_csv(\"./data/evaluation_data/transaction-zipcodes-2022-06-29.csv\",\n",
    "                            dtype={\"zipcode\": str, \"transaction_zipcode\": str})\n",
    "\n",
    "# Clean + preprocess data\n",
    "transactions_df.dropna(inplace=True)\n",
    "transactions_df[\"zipcode\"] = transactions_df[\"zipcode\"].apply(convert_four_digit_zip)\n",
    "transactions_df[\"transaction_zipcode\"] = transactions_df[\"transaction_zipcode\"].apply(convert_four_digit_zip)\n",
    "\n",
    "# Split into multiple dataframes for easy compute\n",
    "rows = range(1000, 11000, 1000)\n",
    "dfs = []\n",
    "\n",
    "for index, row in enumerate(rows):\n",
    "    if index == 0:\n",
    "        dfs.append(transactions_df.iloc[:row])\n",
    "    else:\n",
    "        dfs.append(transactions_df.iloc[rows[index - 1]:row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a42788e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataframe 2\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "Getting dataframe 3\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "Getting dataframe 4\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "Getting dataframe 5\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "Getting dataframe 6\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "Getting dataframe 7\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "Getting dataframe 8\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "Getting dataframe 9\n"
     ]
    }
   ],
   "source": [
    "# Get negative zipcodes by splitting df into multiple\n",
    "# 0 1 2 3 4 5 6 7 8 9\n",
    "for i in range(len(dfs)):\n",
    "    print(\"Getting dataframe \" + str(i))\n",
    "    CURRENT = dfs[i]\n",
    "    neg_zipcodes = []\n",
    "    for index, row in CURRENT.iterrows():\n",
    "        # Keep track of progress\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        negative_data = get_negative(row[\"zipcode\"])\n",
    "        if negative_data == None:\n",
    "            neg_zipcodes.append(None)\n",
    "        else:\n",
    "            neg_zipcodes.append(negative_data[0])\n",
    "    CURRENT.insert(4, \"negative_zipcode\", neg_zipcodes)\n",
    "\n",
    "    NAME = \"transactions_df_\" + str(i) + \".csv\"\n",
    "\n",
    "    CURRENT.to_csv(NAME, index_label=\"main_index\")\n",
    "\n",
    "# Merge back into one dataframe\n",
    "transactions_df = pd.concat(dfs)\n",
    "transactions_df.to_csv(\"transactions_df_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eeb3744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure augmented is unchanged from original\n",
    "transactions_df = pd.read_csv(\"./data/evaluation_data/transaction-zipcodes-2022-06-29.csv\",\n",
    "                             dtype={\"zipcode\": str, \"transaction_zipcode\": str, \"negative_zipcode\": str})\n",
    "transactions_df.dropna(inplace=True)\n",
    "transactions_df[\"zipcode\"] = transactions_df[\"zipcode\"].apply(convert_four_digit_zip)\n",
    "transactions_df[\"transaction_zipcode\"] = transactions_df[\"transaction_zipcode\"].apply(convert_four_digit_zip)\n",
    "transactions_df = transactions_df.reset_index(drop=True)\n",
    "transactions_df_augmented = pd.read_csv(\"./data/evaluation_data/transactions_df_augmented.csv\",\n",
    "                             dtype={\"zipcode\": str, \"transaction_zipcode\": str, \"negative_zipcode\": str})\n",
    "for index, row in transactions_df.iterrows():\n",
    "    if row[\"zipcode\"] != transactions_df_augmented.iloc[index].zipcode or row[\"transaction_zipcode\"] != transactions_df_augmented.iloc[index].transaction_zipcode:\n",
    "            print(\"bad at \" + str(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef926523",
   "metadata": {},
   "source": [
    "UNIT TESTS FOR FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554f1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 5.028s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fceec578898>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RunTests(unittest.TestCase):\n",
    "    def test_get_dma(self):\n",
    "        self.assertEqual(get_dma(\"\"), None)\n",
    "        self.assertEqual(get_dma([]), None)\n",
    "        self.assertEqual(get_dma([\"\"]), None)\n",
    "        self.assertEqual(get_dma([\"2138\"]), None)\n",
    "        self.assertEqual(get_dma(\"2138\"), None)\n",
    "        self.assertEqual(get_dma([\"78750\"]), \"Austin TX\")\n",
    "        self.assertEqual(get_dma(\"78750\"), \"Austin TX\")\n",
    "        self.assertEqual(get_dma(\"02138\"), \"Boston MA-Manchester NH\")\n",
    "        self.assertEqual(get_dma([\"02138\"]), \"Boston MA-Manchester NH\")\n",
    "        self.assertEqual(get_dma([\"78750\", \"78754\", \"78741\"]), \"Austin TX\")\n",
    "        \n",
    "        \n",
    "    def test_split_by_dma(self):\n",
    "        self.assertEqual(split_by_dma([\"78750\"]), [[\"78750\"]])\n",
    "        self.assertEqual(split_by_dma([\"78750\", \"02138\"]), [[\"78750\"], [\"02138\"]])\n",
    "        self.assertEqual(split_by_dma([\"78750\", \"02138\", \"78741\"]), [[\"78750\"], [\"02138\"], [\"78741\"]])\n",
    "        self.assertEqual(split_by_dma([\"78750\", \"78741\", \"02138\", \"02210\", \"78754\", \"02108\", \"02112\"]), \n",
    "                                     [[\"78750\", \"78741\"], [\"02138\", \"02210\"], [\"78754\"], [\"02108\", \"02112\"]])\n",
    "        self.assertEqual(split_by_dma([\"78750\", \"78741\", \"02138\"]), [[\"78750\", \"78741\"], [\"02138\"]])\n",
    "        self.assertEqual(split_by_dma([\"02138\", \"78750\", \"78741\"]), [[\"02138\"], [\"78750\", \"78741\"]])\n",
    "        self.assertEqual(split_by_dma([\"02138\", \"78750\", \"78741\", \"02114\", \"02115\", \"02116\"]), \n",
    "                                     [[\"02138\"], [\"78750\", \"78741\"], [\"02114\", \"02115\", \"02116\"]])\n",
    "        \n",
    "    def test_merge_by_dma(self):\n",
    "        self.assertEqual(merge_by_dma([[\"78750\"]], []), [[\"78750\"]])\n",
    "        self.assertEqual(merge_by_dma([[]], []), [])\n",
    "        self.assertEqual(merge_by_dma([[\"78750\"], [\"02138\"]], []), [[\"78750\"], [\"02138\"]])\n",
    "        self.assertEqual(merge_by_dma([[\"78750\"], [\"02138\"], [\"78754\"]], []), [[\"78750\", \"78754\"], [\"02138\"]])\n",
    "        self.assertEqual(merge_by_dma([[\"78750\"], [\"02138\"], [\"78754\"], [\"78750\"]], []), [[\"78750\", \"78754\", \"78750\"], [\"02138\"]])\n",
    "        self.assertEqual(merge_by_dma([[\"78750\", \"78754\"], [\"02138\", \"02210\"], [\"10007\", \"10008\"]], []), \n",
    "                                         [[\"78750\", \"78754\"], [\"02138\", \"02210\"], [\"10007\", \"10008\"]])\n",
    "        self.assertEqual(merge_by_dma([[\"78750\", \"78754\"], [\"02138\", \"02210\"], [\"10007\", \"10008\"], [\"02108\", \"02112\", \"02116\"]], []), \n",
    "                                         [[\"78750\", \"78754\"], [\"02138\", \"02210\", \"02108\", \"02112\", \"02116\"], [\"10007\", \"10008\"]])\n",
    "        self.assertEqual(merge_by_dma([[\"02110\"], [\"78750\", \"78754\"], [\"02138\", \"02210\"], [\"10007\", \"10008\"], [\"02108\", \"02112\", \"02116\"]], []), \n",
    "                                         [[\"02110\", \"02138\", \"02210\", \"02108\", \"02112\", \"02116\"], [\"78750\", \"78754\"], [\"10007\", \"10008\"]])\n",
    "        \n",
    "    def test_convert_four_digit_zip(self):\n",
    "        self.assertEqual(convert_four_digit_zip(\"1111\"), \"01111\")\n",
    "        self.assertEqual(convert_four_digit_zip(\"0101\"), \"00101\")\n",
    "        self.assertEqual(convert_four_digit_zip(\"78750\"), \"78750\")\n",
    "        \n",
    "    def test_calc_distance(self):\n",
    "        self.assertFalse(calc_distance(\"02138\", \"02138\"))\n",
    "        self.assertFalse(calc_distance(\"78750\", \"78750\"))\n",
    "        self.assertTrue(calc_distance(\"02138\", \"78750\"))\n",
    "        self.assertTrue(calc_distance(\"78750\", \"78704\") < 30)\n",
    "        self.assertFalse(calc_distance(\"02138\", \"78704\") < 30)\n",
    "        \n",
    "    def test_get_negative(self):\n",
    "        self.assertFalse(get_negative(\"78750\")[0] == \"02138\")\n",
    "        self.assertFalse(get_negative(\"78750\")[0] == \"78750\")\n",
    "        self.assertTrue(get_negative(\"78750\")[0] == \"78726\")\n",
    "        self.assertTrue(get_negative(\"02138\")[0] == \"02140\")\n",
    "        \n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41637fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, May 24 2022, 21:28:31) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
